import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt

# Hyperparameters
learning_rate = 0.0005  # Reduced learning rate
training_steps = 200    # Set training steps to 200
batch_size = 256
display_step = 100
num_features = 784  # 28*28 pixels
num_classes = 10    # 0-9 digits
n_hidden_1 = 128    # Number of neurons in the first hidden layer
n_hidden_2 = 256    # Number of neurons in the second hidden layer
dropout_rate = 0.6  # Increased dropout rate

# Suppress TensorFlow warnings (Optional)
import logging
logging.getLogger('tensorflow').setLevel(logging.ERROR)

# Define Dense Layer class with He initialization
class DenseLayer(tf.Module):
    def __init__(self, in_features, out_features, name=None):
        super().__init__(name=name)
        initializer = tf.initializers.HeNormal()
        self.w = tf.Variable(initializer([in_features, out_features]), name="w")
        self.b = tf.Variable(tf.zeros([out_features]), name="b")

    def __call__(self, x):
        return tf.matmul(x, self.w) + self.b

# Define Neural Network class with Dropout and Batch Normalization
class NN(tf.Module):
    def __init__(self, name=None):
        super().__init__(name=name)
        # Define layers
        self.layer1 = DenseLayer(num_features, n_hidden_1, name="layer1")
        self.bn1 = tf.keras.layers.BatchNormalization()  # Batch normalization for layer1
        self.layer2 = DenseLayer(n_hidden_1, n_hidden_2, name="layer2")
        self.bn2 = tf.keras.layers.BatchNormalization()  # Batch normalization for layer2
        self.out_layer = DenseLayer(n_hidden_2, num_classes, name="output")

    def __call__(self, x, training=False):
        # First hidden layer
        x = self.layer1(x)
        x = self.bn1(x, training=training)  # Apply batch normalization
        x = tf.nn.relu(x)
        if training:
            x = tf.nn.dropout(x, rate=dropout_rate)
        
        # Second hidden layer
        x = self.layer2(x)
        x = self.bn2(x, training=training)  # Apply batch normalization
        x = tf.nn.relu(x)
        if training:
            x = tf.nn.dropout(x, rate=dropout_rate)
        
        # Output layer
        x = self.out_layer(x)
        return tf.nn.softmax(x)

    @property
    def trainable_variables(self):
        return self.layer1.variables + self.layer2.variables + self.out_layer.variables

# Cross-entropy loss function
def cross_entropy(y_pred, y_true):
    y_true = tf.one_hot(y_true, depth=num_classes)
    y_pred = tf.clip_by_value(y_pred, 1e-9, 1.0)
    return tf.reduce_mean(-tf.reduce_sum(y_true * tf.math.log(y_pred), axis=1))

# Accuracy metric function
def accuracy(y_pred, y_true):
    y_pred = tf.argmax(y_pred, axis=1, output_type=tf.int64)
    y_true = tf.cast(y_true, tf.int64)  # Cast y_true to int64
    correct_predictions = tf.equal(y_pred, y_true)
    return tf.reduce_mean(tf.cast(correct_predictions, tf.float32)).numpy()

# Function to train the neural network
def train(nn, input_x, output_y):
    optimizer = tf.optimizers.Adam(learning_rate)
    with tf.GradientTape() as tape:
        pred = nn(input_x, training=True)
        loss = cross_entropy(pred, output_y)
    gradients = tape.gradient(loss, nn.trainable_variables)
    optimizer.apply_gradients(zip(gradients, nn.trainable_variables))
    return loss.numpy()

# Load and prepare the MNIST dataset
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()

# Normalize and reshape the data
x_train = x_train.reshape(-1, num_features).astype(np.float32) / 255.0
x_test = x_test.reshape(-1, num_features).astype(np.float32) / 255.0
y_train = y_train.astype(np.uint8)
y_test = y_test.astype(np.uint8)

# Instantiate the neural network
neural_net = NN(name="mnist_model")

# Prepare the training dataset
train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))
train_data = train_data.shuffle(buffer_size=5000).batch(batch_size).prefetch(1)

# Training loop
loss_history = []
accuracy_history = []
display_steps = []

for step, (batch_x, batch_y) in enumerate(train_data.take(training_steps)):
    loss = train(neural_net, batch_x, batch_y)

    if step % display_step == 0:
        pred = neural_net(batch_x, training=False)  # Disable dropout during inference
        acc = accuracy(pred, batch_y)
        loss_history.append(loss)
        accuracy_history.append(acc)
        display_steps.append(step)
        print(f"Step {step}, Loss: {loss:.4f}, Accuracy: {acc:.4f}")

# Plotting the loss and accuracy
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(display_steps, loss_history, color='g')
plt.title("Loss over Time")
plt.xlabel("Training Steps")
plt.ylabel("Loss")
plt.grid(True)

plt.subplot(1, 2, 2)
plt.plot(display_steps, accuracy_history, color='b')
plt.title("Accuracy over Time")
plt.xlabel("Training Steps")
plt.ylabel("Accuracy")
plt.grid(True)

plt.show()

# Check for data length mismatch
if len(display_steps) == len(loss_history) == len(accuracy_history):
    plt.show()
else:
    print("Mismatch in the length of data lists. Check the training loop.")

# Calculate the accuracy on the test set
acc = accuracy(neural_net(x_test), y_test)
print(f"Accuracy on the test set: {acc}")

# Select 5 random images from the test set
np.random.seed(42)  # For reproducibility
random_indices = np.random.choice(x_test.shape[0], 5, replace=False)

plt.figure(figsize=(10, 5))

for i, idx in enumerate(random_indices):
    x_sample = x_test[idx].reshape(1, 784)
    y_sample = y_test[idx]
    
    # Predict the label using the neural network
    prediction = np.argmax(neural_net(x_sample), axis=1)
    
    # Plot the image
    plt.subplot(1, 5, i + 1)
    plt.imshow(x_sample.reshape(28, 28), cmap='gray')
    plt.title(f"True: {y_sample}\nPred: {prediction[0]}")
    plt.axis('off')

plt.show()

# Test a specific image
sample_num = 64
x1 = x_test[sample_num].reshape(28, 28)
print(f"True label for sample {sample_num}: {y_test[sample_num]}")
plt.imshow(x1, cmap='gray')
plt.title(f"True label: {y_test[sample_num]}")
plt.axis('off')
plt.show()

